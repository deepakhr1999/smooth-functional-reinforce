{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import gym\n",
    "import torch\n",
    "from network import ContinuousPolicyNetwork\n",
    "from spsa import get_alpha, get_delta, update_weights, perturb_policy, Module, revert_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(policy: Module, env: gym.Env, gamma: float) -> float:\n",
    "    state, _ = env.reset()\n",
    "    tdx = 0\n",
    "    G_new = 0\n",
    "    while True:\n",
    "        action, log_prob = policy.sample(state)\n",
    "        act = action.item()\n",
    "        state, reward, term, trunc, _ = env.step([act])\n",
    "        done = term or trunc\n",
    "        G_new += gamma**tdx * reward\n",
    "        tdx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return G_new\n",
    "\n",
    "def spsa(env, policy, seed, num_episodes=20000, gamma=0.99, num_trials=10):\n",
    "    start = time.time()\n",
    "    results = []\n",
    "    for episode in range(num_episodes):\n",
    "        with torch.no_grad():\n",
    "            # sample perturbations\n",
    "            perturbed_policy, old_params, perts = perturb_policy(\n",
    "                policy, delta=get_delta(episode)\n",
    "            )\n",
    "\n",
    "            # simulate for num_trials\n",
    "            rewards = []\n",
    "            for _ in range(num_trials):\n",
    "                rewards.append(simulate(perturbed_policy, env, gamma))\n",
    "\n",
    "            # revert weights of the policy\n",
    "            policy = revert_weights(perturbed_policy, old_params)\n",
    "\n",
    "            # update weights according to the paper\n",
    "            avg_reward = sum(rewards) / len(rewards)\n",
    "            policy = update_weights(policy, avg_reward, perts, episode)\n",
    "\n",
    "        results.append(avg_reward)\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            avg = sum(results[-1000:]) / min(len(results), 1000)\n",
    "            print(\n",
    "                f\"Seed: {seed}, time: {time.time() - start}, Episode {episode}, Average Reward: {avg}\"\n",
    "            )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepakhr/miniconda3/envs/py311/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0, time: 0.14887499809265137, Episode 0, Average Reward: -572.6721596333452\n",
      "Seed: 0, time: 14.804646968841553, Episode 100, Average Reward: -557.8625315164915\n",
      "Seed: 0, time: 29.41745686531067, Episode 200, Average Reward: -567.9334121502192\n",
      "Seed: 0, time: 44.33139681816101, Episode 300, Average Reward: -573.975645558429\n",
      "Seed: 0, time: 58.94672393798828, Episode 400, Average Reward: -576.8748722377385\n",
      "Seed: 0, time: 73.55594301223755, Episode 500, Average Reward: -577.4157815431045\n",
      "Seed: 0, time: 87.99592995643616, Episode 600, Average Reward: -577.3072614912123\n",
      "Seed: 0, time: 102.22212290763855, Episode 700, Average Reward: -578.0279180520799\n",
      "Seed: 0, time: 117.15559411048889, Episode 800, Average Reward: -578.608784570868\n",
      "Seed: 0, time: 131.30128288269043, Episode 900, Average Reward: -578.4083520649137\n",
      "Seed: 0, time: 145.79238390922546, Episode 1000, Average Reward: -577.859921330252\n",
      "Seed: 0, time: 160.3004801273346, Episode 1100, Average Reward: -580.1247029298187\n",
      "Seed: 0, time: 174.26425099372864, Episode 1200, Average Reward: -580.0801655964516\n",
      "Seed: 0, time: 188.88356399536133, Episode 1300, Average Reward: -579.148921990639\n",
      "Seed: 0, time: 203.03680205345154, Episode 1400, Average Reward: -578.2555668888645\n",
      "Seed: 0, time: 217.29583096504211, Episode 1500, Average Reward: -577.647668718706\n",
      "Seed: 0, time: 231.54859900474548, Episode 1600, Average Reward: -577.5103740870903\n",
      "Seed: 0, time: 246.5843768119812, Episode 1700, Average Reward: -577.0021905314268\n",
      "Seed: 0, time: 261.532958984375, Episode 1800, Average Reward: -576.2675868353157\n",
      "Seed: 0, time: 276.23776388168335, Episode 1900, Average Reward: -575.7341623277908\n",
      "Seed: 0, time: 291.0117208957672, Episode 2000, Average Reward: -575.0914443837306\n",
      "Seed: 0, time: 305.72442984580994, Episode 2100, Average Reward: -574.7082607143981\n",
      "Seed: 0, time: 320.39267587661743, Episode 2200, Average Reward: -574.5389147695755\n",
      "Seed: 0, time: 335.01667881011963, Episode 2300, Average Reward: -574.9917293466715\n",
      "Seed: 0, time: 349.7194528579712, Episode 2400, Average Reward: -574.8611975980456\n",
      "Seed: 0, time: 364.2375679016113, Episode 2500, Average Reward: -574.6039015514345\n",
      "Seed: 0, time: 378.80466413497925, Episode 2600, Average Reward: -574.2219916965145\n",
      "Seed: 0, time: 393.33618903160095, Episode 2700, Average Reward: -572.8783164104285\n",
      "Seed: 0, time: 407.7645628452301, Episode 2800, Average Reward: -571.7558898447309\n",
      "Seed: 0, time: 422.3561098575592, Episode 2900, Average Reward: -570.3592161531153\n",
      "Seed: 0, time: 436.8515667915344, Episode 3000, Average Reward: -568.4919946729897\n",
      "Seed: 0, time: 451.33250093460083, Episode 3100, Average Reward: -565.0561897307379\n",
      "Seed: 0, time: 465.5529510974884, Episode 3200, Average Reward: -560.8111713045496\n",
      "Seed: 0, time: 479.88030099868774, Episode 3300, Average Reward: -556.2731999626984\n",
      "Seed: 0, time: 494.23109102249146, Episode 3400, Average Reward: -553.5193208016651\n",
      "Seed: 0, time: 508.62499475479126, Episode 3500, Average Reward: -551.1686562534784\n",
      "Seed: 0, time: 523.1398310661316, Episode 3600, Average Reward: -550.1434493578353\n",
      "Seed: 0, time: 537.6113941669464, Episode 3700, Average Reward: -550.8021585097971\n",
      "Seed: 0, time: 551.9487109184265, Episode 3800, Average Reward: -550.6865768664051\n",
      "Seed: 0, time: 566.4111609458923, Episode 3900, Average Reward: -550.5125565403091\n",
      "Seed: 0, time: 580.6983189582825, Episode 4000, Average Reward: -552.0913126017401\n",
      "Seed: 0, time: 594.9332938194275, Episode 4100, Average Reward: -554.3557286328944\n",
      "Seed: 0, time: 609.2299959659576, Episode 4200, Average Reward: -559.0350476592945\n",
      "Seed: 0, time: 623.6511569023132, Episode 4300, Average Reward: -563.8567518607366\n",
      "Seed: 0, time: 638.1990830898285, Episode 4400, Average Reward: -565.5675040426348\n",
      "Seed: 0, time: 652.2450168132782, Episode 4500, Average Reward: -569.026484919408\n",
      "Seed: 0, time: 666.6190068721771, Episode 4600, Average Reward: -571.1239473910632\n",
      "Seed: 0, time: 681.022451877594, Episode 4700, Average Reward: -570.9674477307784\n",
      "Seed: 0, time: 695.3816277980804, Episode 4800, Average Reward: -571.5321580154468\n",
      "Seed: 0, time: 709.941174030304, Episode 4900, Average Reward: -572.7773873182383\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "iterations = 5000\n",
    "policy = ContinuousPolicyNetwork()\n",
    "env = gym.make(\"Pendulum-v1\")\n",
    "results = spsa(env, policy, seed, iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
